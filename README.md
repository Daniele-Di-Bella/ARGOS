# ğŸ• ARGOS: A Retrieval-augmented GeneratiOn approach for Scientific communication

## ğŸ“š Overview
**ARGOS** is a modular Snakemake workflow implementing a Retrieval-Augmented Generation (RAG) pipeline using documents retrieved from a local Zotero library. It automates: 
1. **Document Retrieval** from Zotero using its API.
2. **Answer Generation** and **Answer Proofreading** employing an LLM. The model now in use is OpenAI's GPT-4.1. 
3. **Evaluation** of the generated answer versus a reference. This function was added for initial tests of the app. 

## Requirements
- Python â‰¥ 3.8  
- Snakemake  
- Zotero with local storage and API access  
- OpenAI API key (or any other key, if the employed LLM is not an OpenAI model)

## Installation
Clone the repository and install dependencies:
```bash
git clone https://github.com/<username>/ARGOS.git
cd ARGOS
```
Create a virtual environment and install required packages: 
```bash
conda create -n ARGOS python=3.9 snakemake
conda activate ARGOS
pip install -r requirements.txt
```

## Folder structure
```bash
project_root/
â”‚
â”œâ”€â”€ Snakefile
â”œâ”€â”€ config.yaml
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ API_keys.py               # Contains API credentials (Zotero key, library ID, OpenAI key)
â”‚   â”œâ”€â”€ zotero_retriever.py       # Script to retrieve PDFs/HTMLs from Zotero
â”‚   â”œâ”€â”€ RAG.py                    # Core Retrieval-Augmented Generation logic
â”‚   â””â”€â”€ evaluation.py             # Evaluation script comparing RAG output vs reference
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ <keywords>/               # Zotero-retrieved documents (PDF/HTML) for given keyword
â”‚
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ <keywords>/               # Output directory for each keyword
â”‚       â”œâ”€â”€ <question>.md            # Main RAG-generated answer
â”‚       â”œâ”€â”€ <keywords>_RT.md         # Manually added reference answer (used in evaluation)
â”‚       â”œâ”€â”€ <question>[Eval].md      # Markdown evaluation results
â”‚       â””â”€â”€ <question>[Eval].csv     # Optional CSV with evaluation metrics (if enabled)
â”‚
â””â”€â”€ .snakemake/                # (auto-generated by Snakemake to track workflow state)
```

## Configuration
Insert your keys in `API_keys.py` then edit the `config.yaml` file to set your parameters before running the entire pipeline. Below its an example of an extremely basic `config.yaml` file. 
```yaml
keywords: "climate change"  
language: "English"
target_audience: "Glaciologists"
question: "What are the recent trends in Arctic sea ice decline?"
model: "gpt-4.1"
vector_store_type: "faiss"
k_chunks: 50 
```
## Workflow Structure
The workflow consists of the following Snakemake rules:

1. `zotero_retrieval` -- Retrieves documents using `scripts/zotero_retriever.py` and saves files in `data/{keywords}/`.
2. `RAG` -- Embeds documents, retrieves top-k chunks, generates an answer and proofreads it. The output is saved as Markdown in `outputs/{keywords}/`
3. `evaluation` -- Compares generated output to a reference answer (`{keywords}_RT.md`). Saves results in Markdown and optionally CSV. 
4. `all` -- Ensures the complete pipeline runs end-to-end.

## Usage
Execute the pipeline with:
```bash
snakemake --cores <N> --untill <rule>
```
Replace `N` with the number of available cores and `rule` with the step of the pipeline you want to reach.

## Output Structure
Retrieved documents: `data/{keywords}/`
Generated answer: `outputs/{keywords}/{question}.md`
Evaluation report: `outputs/{keywords}/{question}[Eval].md`
Optional metrics: CSV file in the same output directory

## License & Contact
License: MIT
Author: Daniele Di Bella (daniele.dibella99@gmail.com)
